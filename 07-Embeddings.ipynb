{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from numpy import dot, array\n",
    "from numpy.linalg import norm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Este é o primeiro documento. Ele contém informações importantes sobre o projeto.\",\n",
    "    \"Este é o segundo documento. Ele contém informações importantes sobre o projeto.\",\n",
    "    \"O terceiro documento oferece uma visão geral dos resultados esperados e métricas de sucesso.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunks gerados:\n",
      "Chunk 1: Este é o primeiro documento. Ele contém\n",
      "Chunk 2: contém informações importantes sobre o projeto.\n",
      "Chunk 3: Este é o segundo documento. Ele contém informações\n",
      "Chunk 4: importantes sobre o projeto.\n",
      "Chunk 5: O terceiro documento oferece uma visão geral dos\n",
      "Chunk 6: geral dos resultados esperados e métricas de\n",
      "Chunk 7: de sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Dividir documentos em chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,  \n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.create_documents(documents)\n",
    "\n",
    "print(\"\\nChunks gerados:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número total de chunks: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNúmero total de chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "#print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedded_chunks = embeddings.embed_documents([chunk.page_content for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3x/j5lxxqwd671dhlhn57rtnkyr0000gn/T/ipykernel_46922/1048288091.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274a1d92667a461090b76d8f3e1ee887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f02e26266a4cec923b14684926a73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6c8c2f4abb49eb9a6fa45f95786fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d8453bfb1a43c4a3192e7aa429bfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f41f1cad354031a7da376e708bda54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9f337a8a3c48058cf54d2818806cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac808ec8837470b872abda8dc908e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49965cd43934513aaa7af617399e22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430cd139b98f46eebf306f0fa9af029d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b67a1626dc4fe88d54abda9b3df136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb94f3068824b47ab7331a6bba007fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista para armazenar os embeddings\n",
    "embedded_chunks = []\n",
    "for chunk in chunks:\n",
    "    # A biblioteca de embeddings transforma o texto em um vetor numérico\n",
    "    embedding = embeddings_model.embed_documents([chunk.page_content])[0]\n",
    "    embedded_chunks.append(embedding)\n",
    "    print(f\"Embedding do Chunk {len(embedded_chunks)} gerado (tamanho: {len(embedding)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar os embeddings gerados\n",
    "print(\"\\nEmbeddings gerados (mostrando apenas os primeiros 5 elementos de cada):\")\n",
    "for i, embed in enumerate(embedded_chunks):\n",
    "    print(f\"Embedding {i+1}: {embed[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNúmero de elementos em cada embedding: {len(embedded_chunks[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return dot(vec1, vec2) / (norm(vec1) * norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimilaridades entre todos os chunks:\")\n",
    "similarities = []\n",
    "for i in range(len(embedded_chunks)):\n",
    "    for j in range(i + 1, len(embedded_chunks)):\n",
    "        similarity = cosine_similarity(embedded_chunks[i], embedded_chunks[j])\n",
    "        similarities.append((i, j, similarity))\n",
    "        print(f\"Similaridade entre o chunk {i+1} e o chunk {j+1}: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_chunks_array = array(embedded_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(embedded_chunks_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c='blue', edgecolor='k', s=50)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    plt.text(pca_result[i, 0], pca_result[i, 1], f'Chunk {i+1}', fontsize=12)\n",
    "for (i, j, similarity) in similarities:\n",
    "    plt.plot([pca_result[i, 0], pca_result[j, 0]], [pca_result[i, 1], pca_result[j, 1]], 'k--', alpha=similarity)\n",
    "    mid_x = (pca_result[i, 0] + pca_result[j, 0]) / 2\n",
    "    mid_y = (pca_result[i, 1] + pca_result[j, 1]) / 2\n",
    "    plt.text(mid_x, mid_y, f'{similarity:.2f}', fontsize=8, color='green')\n",
    "plt.title('Visualização dos Embeddings com PCA')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=2, max_iter=300)\n",
    "tsne_result = tsne.fit_transform(embedded_chunks_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c='red', edgecolor='k', s=50)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    plt.text(tsne_result[i, 0], tsne_result[i, 1], f'Chunk {i+1}', fontsize=12)\n",
    "for (i, j, similarity) in similarities:\n",
    "    plt.plot([tsne_result[i, 0], tsne_result[j, 0]], [tsne_result[i, 1], tsne_result[j, 1]], 'k--', alpha=similarity)\n",
    "    mid_x = (tsne_result[i, 0] + tsne_result[j, 0]) / 2\n",
    "    mid_y = (tsne_result[i, 1] + tsne_result[j, 1]) / 2\n",
    "    plt.text(mid_x, mid_y, f'{similarity:.2f}', fontsize=8, color='green')\n",
    "plt.title('Visualização dos Embeddings com t-SNE')\n",
    "plt.xlabel('Dimensão 1')\n",
    "plt.ylabel('Dimensão 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
